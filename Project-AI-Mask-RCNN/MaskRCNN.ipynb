{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deneme.ipynb","provenance":[],"authorship_tag":"ABX9TyM+0NpvLJIY8LYWfx9ynARY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import mediapipe\n"],"metadata":{"id":"wfsbcDRIGQxn","executionInfo":{"status":"error","timestamp":1659335429512,"user_tz":-180,"elapsed":5,"user":{"displayName":"Özgür Çetin","userId":"15568653990884069427"}},"outputId":"59eef0d1-ec3e-409b-a217-241b99e435d7","colab":{"base_uri":"https://localhost:8080/","height":304}},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9b95ffcaa4fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oxv_3WiOZmz6","executionInfo":{"status":"ok","timestamp":1658908633863,"user_tz":-180,"elapsed":21968,"user":{"displayName":"Özgür Çetin","userId":"15568653990884069427"}},"outputId":"4da40a75-ffab-4a44-eb4d-2e427a1fadca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%tensorflow_version 1.x\n","!pip install --upgrade h5py==2.10.0\n","!git clone https://github.com/pysource7/Mask_RCNN\n","import sys\n","sys.path.append(\"/content/Mask_RCNN/demo\")\n","%matplotlib inline"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ORkc5s7ZtvO","executionInfo":{"status":"ok","timestamp":1658908666299,"user_tz":-180,"elapsed":17910,"user":{"displayName":"Özgür Çetin","userId":"15568653990884069427"}},"outputId":"480577d5-3902-4af1-c92d-7d87d388d4ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: Tensorflow 1 is deprecated, and support will be removed on August 1, 2022.\n","After that, `%tensorflow_version 1.x` will throw an error.\n","\n","Your notebook should be updated to use Tensorflow 2.\n","See the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.\n","\n","TensorFlow 1.x selected.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 30.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n","Installing collected packages: h5py\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","Successfully installed h5py-2.10.0\n","Cloning into 'Mask_RCNN'...\n","remote: Enumerating objects: 1016, done.\u001b[K\n","remote: Total 1016 (delta 0), reused 0 (delta 0), pack-reused 1016\u001b[K\n","Receiving objects: 100% (1016/1016), 139.69 MiB | 15.09 MiB/s, done.\n","Resolving deltas: 100% (596/596), done.\n"]}]},{"cell_type":"code","source":["from train_mask_rcnn_demo import *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"LewF-xIBqQpz","executionInfo":{"status":"error","timestamp":1658908681909,"user_tz":-180,"elapsed":508,"user":{"displayName":"Özgür Çetin","userId":"15568653990884069427"}},"outputId":"2bc86aaa-e3f2-41de-fe2d-cfe5d5883b68"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-9818552f8ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain_mask_rcnn_demo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train_mask_rcnn_demo'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"0lLEr-YfZttX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract Images\n","images_path = \"/content/drive/MyDrive/data.zip\"\n","annotations_path = \"/content/annotations.json\"\n","\n","extract_images(os.path.join(\"/content/\",images_path), \"/content/dataset\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"ym3DIpApZtrB","executionInfo":{"status":"error","timestamp":1658904976879,"user_tz":-180,"elapsed":426,"user":{"displayName":"Özgür Çetin","userId":"15568653990884069427"}},"outputId":"aa7e847a-b441-4512-e397-2c396433a531"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-123f500a43d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mannotations_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/annotations.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mextract_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'extract_images' is not defined"]}]},{"cell_type":"code","source":["dataset_train = load_image_dataset(os.path.join(\"/content/\", annotations_path), \"/content/dataset\", \"train\")\n","dataset_val = load_image_dataset(os.path.join(\"/content/\", annotations_path), \"/content/dataset\", \"val\")\n","class_number = dataset_train.count_classes()\n","print('Train: %d' % len(dataset_train.image_ids))\n","print('Validation: %d' % len(dataset_val.image_ids))\n","print(\"Classes: {}\".format(class_number))"],"metadata":{"id":"6qYjUgMWZton"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load image samples\n","display_image_samples(dataset_train)"],"metadata":{"id":"0wadD2rRZtmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Configuration\n","config = CustomConfig(class_number)\n","#config.display()\n","model = load_training_model(config,_)"],"metadata":{"id":"tXp8pNX3ZtkG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start Training\n","# This operation might take a long time.\n","train_head(model, dataset_train, dataset_train, config,5)"],"metadata":{"id":"Sk56bKv0ZtiE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Test Model\n","# The latest trained model will be loaded\n","test_model, inference_config = load_test_model(class_number,_)"],"metadata":{"id":"JI9yGUCIaB8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_random_image(test_model, dataset_val, inference_config)"],"metadata":{"id":"O60_lo6taB6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/Mask_RCNN/video_demo.py /content/drive/MyDrive/f1.mp4"],"metadata":{"id":"6GStIrxJaB0q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import time\n","capture = cv2.VideoCapture(\"/content/drive/MyDrive/f1.mp4\")\n","width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH) + 0.5)\n","height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT) + 0.5)\n","size = (height, width)\n","fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","# output_movie = cv2.VideoWriter('Zoo-video-masked.avi', fourcc, 30.0, (1920,1080))\n","video = cv2.VideoWriter(\"Zoo_video_masked.avi\", cv2.VideoWriter_fourcc(*'DIVX'),fps, (1152, 1152))\n","# Constructing code of the codec to be used in the function VideoWriter\n","# writer = cv2.VideoWriter('Zoo-video-masked.mp4', fourcc, 20, (1920, 1080))\n","count=0\n","while True:\n","    # Capture frame-by-frame\n","    ret, frame = capture.read()\n","    if not ret:\n","        break\n","\n","    results = model.detect([frame], verbose=1)\n","    r = results[0]\n","\n","    boxes = r['rois']\n","    masks = r['masks']\n","    class_ids = r['class_ids']\n","    scores = r['scores']\n","\n","    # Run detection\n","    start = time.time()\n","    masked_image = vc.display_instances(frame, boxes, masks, class_ids, class_names, scores)\n","    end = time.time()\n","    print(\"Inference time: {:.2f}s\".format(end - start))\n","\n","    # Display the resulting frame\n","    # cv2.imshow('', masked_image)\n","    #save image\n","    # writer = cv2.VideoWriter('Zoo-video-masked.mp4', fourcc, 30, (frame.shape[1], frame.shape[0]), True)\n","    #we are saving the image as \"Masked-image.jpg under visualizeCustom code\"\n","    #this image file we are writing inour videowriter object\n","    print(\"here,\",type(masked_image))\n","    img=cv2.imread(\"Masked-image.jpg\")\n","    print(img.shape)\n","    video.write(img)\n","    # output_movie.write(masked_image)\n","    count+=1\n","    print(\"count:\",count)\n","    # if cv2.waitKey(1) & 0xFF == ord('q'):\n","    #     break\n","\n","# When everything done, release the capture\n","print(\"WARNING\")\n","cv2.destroyAllWindows()\n","capture.release()\n","video.release()\n","# cv2.destroyAllWindows()"],"metadata":{"id":"vmILX2OQaF5J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# example of inference with a pre-trained coco model\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from mrcnn.visualize import display_instances\n","from mrcnn.config import Config\n","from mrcnn.model import MaskRCNN\n"," \n","# define 81 classes that the coco model knowns about\n","class_names = [\"ferrari\",\"mclaren,\",\"mercedes\",\"rebull\"]\n"," \n","# define the test configuration\n","class TestConfig(Config):\n","     NAME = \"test\"\n","     GPU_COUNT = 1\n","     IMAGES_PER_GPU = 1\n","     NUM_CLASSES = 1 + 4\n"," \n","# define the model\n","rcnn = MaskRCNN(mode='inference', model_dir='./', config=TestConfig())\n","# load coco model weights\n","rcnn.load_weights('/content/gdrive/MyDrive/pysource_mrcnn_pro/object20211027T2145/mask_rcnn_object_0005.h5', by_name=True)\n","# load photograph\n","img = load_img('/content/indir.jpg')\n","img = img_to_array(img)\n","# make prediction\n","results = rcnn.detect([img], verbose=0)\n","# get dictionary for first prediction\n","r = results[0]\n","# show photo with bounding boxes, masks, class labels and scores\n","display_instances(img, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])"],"metadata":{"id":"PGRLa1LRaF29"},"execution_count":null,"outputs":[]}]}